# .env file

# How to use?
# make a copy of this file and name it ".env", then modify the values
# the .env.example file will never be loaded by the app

## --------------------------------------------------------------------------------------
## General Configuration
## --------------------------------------------------------------------------------------

# allowed: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL=INFO

# to create a gradio shared link set this value to True
GRADIO_SHARED=False

# development option, which just returns an image with the provided parameters
NO_AI=False

## --------------------------------------------------------------------------------------
## Token Configuration
## --------------------------------------------------------------------------------------

# token users get when they use the app, if you want to restrict the usage of the app
# you can set this to a value > 0, if you want to disable the token system, set this to 0
INITIAL_GENERATION_TOKEN=10

# the time user needs to wait to receive new token (in minutes)
NEW_TOKEN_WAIT_TIME=10

# if activated user can share images to train models / lora and gain token
ALLOW_UPLOAD=False

## --------------------------------------------------------------------------------------
## Feature: Prompt Magic
## --------------------------------------------------------------------------------------
# Server where ollama is running, if not specified, connect to localhost
#OLLAMA_SERVER=

# Model used for Prompt Magic and NSFW detection
OLLAMA_MODEL=llava
# Turn on or off Promptmagic and prompt rewrite to avoid nsfw
PROMPTMAGIC=True

## --------------------------------------------------------------------------------------
## Feature: Share Links for Token
## --------------------------------------------------------------------------------------
# if set to 0 feature is deactivated
FEATURE_SHARING_LINK_NEW_TOKEN = 3

## --------------------------------------------------------------------------------------
## Feature: Upload Image for Trainig to get new Token
## --------------------------------------------------------------------------------------
# if set to 0 feature is deactivated
FEATURE_UPLOAD_IMAGE_NEW_TOKEN = 10
## --------------------------------------------------------------------------------------
## Generation Configuration
## --------------------------------------------------------------------------------------

# in order to use the flux model you need to create a token with read rights for huggingface and 
# acceppt the licnce agreement of black-forest-labs here:
# https://huggingface.co/black-forest-labs/FLUX.1-schnell
HUGGINGFACE_TOKEN=your_token_here

# the folder which is used to store models loaded from internet and reload form there
# if you have multiple ai projects, i suggest to use a ahred forlder for all projects
MODEL_DIRECTORY=./models

# the folder which is used to store the output images
# if not set, no output will be saved
OUTPUT_DIRECTORY=./output

# this is the default model, if you want to use another model, you can change it here
# you can use the model name from huggingface or a local path to a safetensors file
# you can also use a url to a safetensors file
# if you use a url, the model will be downloaded to the MODEL_DIRECTORY and loaded from there
# if you use a local path, the model will be loaded from there
# if you use a model name from huggingface, the model will be downloaded to the MODEL_DIRECTORY and loaded from there
GENERATION_MODEL=black-forest-labs/FLUX.1-dev
GENERATION_STEPS=50
GENERATION_GUIDANCE=7.5

# GENERATION_MODEL=black-forest-labs/FLUX.1-schnell
# GENERATION_STEPS=4
# GENERATION_GUIDANCE=0

GENERATION_ASPECT_SQUARE=1024x1024
GENERATION_ASPECT_LANDSCAPE=1152x768
GENERATION_ASPECT_PORTRAIT=768x1152



# default model is flux, but fallback (if not enough GPU you can use SDXL)
# USE_SDXL=True
# good for comics
# GENERATION_MODEL=stabilityai/sdxl-turbo
# GENERATION_STEPS=1
# GENERATION_GUIDANCE=0
# GENERATION_ASPECT_SQUARE=512x512
# GENERATION_ASPECT_LANDSCAPE=768x512
# GENERATION_ASPECT_PORTRAIT=512x768


## --------------------------------------------------------------------------------------
## MEMORY Optimization ##
## --------------------------------------------------------------------------------------
MAX_IMAGES=2

## don't mix the following settings! ##

# Memory usage optimization -> use on first out of memory while rendering
GPU_ALLOW_XFORMERS=True

# Split calculation in smaller pieces -> slower! activate if you get out of memory while rendering
GPU_ALLOW_ATTENTION_SLICING=False

# Uses CPU and normal Memory (not GPU) also for Model handling -> activate if you get out of memory on model loading (warmup)
GPU_ALLOW_MEMORY_OFFLOAD=False

PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True